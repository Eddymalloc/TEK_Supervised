{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4aedfdd-146c-4dc3-b702-ce383dbb937e",
   "metadata": {},
   "source": [
    "# PART 3: Prediction of the winner of an NBA game\n",
    "\n",
    "The goal of this exercise is to ...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e2418-fd73-4c70-b056-4d49b0bda181",
   "metadata": {},
   "source": [
    "## Studying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9c6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import section\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a74ea34-b670-42c6-ad19-419f3a7c084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's now loads the different datasets\n",
    "\"\"\"\n",
    "\n",
    "# Load the datasets\n",
    "X_train = np.load('X_train.npy') #features\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy') #labels\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99922aaa-9031-458f-afed-b713794a3116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set features shape: (500, 50)\n",
      "Test set features shape: (500, 50)\n",
      "Training set labels shape: (500,)\n",
      "Test set labels shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the loaded arrays to understand the dimensions of the data\n",
    "print(\"Training set features shape:\", X_train.shape)\n",
    "print(\"Test set features shape:\", X_test.shape)\n",
    "print(\"Training set labels shape:\", y_train.shape)\n",
    "print(\"Test set labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3ee27-a696-4ace-92cc-7800d61081bb",
   "metadata": {},
   "source": [
    "---\n",
    "We now know that there are 500 samples under 50 different features on both of the features sets\n",
    "\n",
    "And we have 500 samples on the labels sets\n",
    "\n",
    "Now let's study some features on the datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a659c0-54d7-4510-a562-53ed1504405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Mean:  [-0.09394964  0.29162237  0.01315227 -0.10866658  0.29876652 -0.04194446\n",
      " -0.27063616 -0.01383477 -0.01765614  0.12838712  0.04927599 -0.04291361\n",
      " -0.13972603 -0.04933297  0.10869843 -0.04044432 -0.14213375  0.01072076\n",
      "  0.09881601  0.13244445  0.05321012  0.03624287  0.10451249  0.25611365\n",
      "  0.10852024 -0.1103403   0.10137301  0.10943872  0.07175347  0.21231416\n",
      " -0.04600741  0.07674707  0.08265513 -0.00691493 -0.03347023 -0.0244771\n",
      "  0.06785085  0.06928688  0.19024655 -0.09204261  0.08997888  0.14340439\n",
      " -0.14356795  0.04574898  0.10034907  0.02223365  0.03351004  0.14728103\n",
      "  0.24826058  0.21036759]\n",
      "Features Std Dev:  [2.874549   4.20182198 4.16172174 2.88975104 2.84355854 3.02342542\n",
      " 2.97198526 2.84598783 2.83291862 4.23691427 2.78059374 2.85605665\n",
      " 2.95017511 2.92699069 2.88631273 2.92642427 2.86696164 2.95628739\n",
      " 2.80475421 4.01297811 4.10906207 2.87031161 2.93980393 4.01251758\n",
      " 4.0906219  2.85806035 2.86522846 2.93501005 2.97859072 2.90846665\n",
      " 4.16658949 2.95393493 2.91310581 2.92570217 2.95111339 2.90620016\n",
      " 2.94632081 2.89656325 4.40847304 2.79429115 2.87688984 2.86244272\n",
      " 2.85266638 4.23914126 2.96477917 2.77393591 2.93025161 2.93959979\n",
      " 2.89557329 2.96323997]\n",
      "Features Min:  [ -4.98760699 -11.27125    -11.00236721  -4.98917579  -4.97607944\n",
      "  -4.98374497  -4.96891423  -4.99316188  -4.96169769 -12.7800372\n",
      "  -4.99628153  -4.93363915  -4.93647726  -4.97884026  -4.99388195\n",
      "  -4.9647754   -4.97443585  -4.99101883  -4.95522002 -12.29217176\n",
      " -11.10029187  -4.98608146  -4.94406937 -11.18354543 -11.74886508\n",
      "  -4.94748663  -4.964886    -4.96715748  -4.95662845  -4.99235329\n",
      " -12.692863    -4.97964311  -4.99964177  -4.98680265  -4.97216334\n",
      "  -4.99714815  -4.96986242  -4.99746643 -10.76438091  -4.97689987\n",
      "  -4.9977358   -4.98205051  -4.99904008 -11.19688426  -4.97631338\n",
      "  -4.99468016  -4.99208159  -4.98095017  -4.98784518  -4.98967757]\n",
      "Features Max:  [ 4.9991007  15.69903736 11.19610555  4.97505197  4.96909416  4.99123483\n",
      "  4.99513644  4.92693255  4.98247767 11.41897626  4.99380718  4.98854188\n",
      "  4.99187284  4.9653053   4.94622487  4.99886787  4.99311991  4.99890047\n",
      "  4.98938845  9.73590187 10.32549953  4.99545955  4.97652311 12.88057305\n",
      " 10.20249312  4.90033355  4.9915234   4.99526336  4.98538327  4.98234064\n",
      " 12.03651934  4.99843248  4.99539623  4.94931775  4.98074477  4.9536331\n",
      "  4.99814941  4.99946523 12.66402272  4.99028278  4.96847388  4.99584989\n",
      "  4.9616585  11.8154215   4.99610162  4.9884142   4.99385158  4.98260808\n",
      "  4.99635639  4.99909524]\n",
      "Label Distribution:  {-1.0: 256, 1.0: 244}\n",
      "Labels Mean:  -0.024\n",
      "Labels Std Dev:  0.9997119585160518\n",
      "Labels Min:  -1.0\n",
      "Labels Max:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Basic statistics for features\n",
    "print(\"Features Mean: \", np.mean(X_train, axis=0))\n",
    "print(\"Features Std Dev: \", np.std(X_train, axis=0))\n",
    "print(\"Features Min: \", np.min(X_train, axis=0))\n",
    "print(\"Features Max: \", np.max(X_train, axis=0))\n",
    "\n",
    "# Check for class imbalance\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"Label Distribution: \", dict(zip(unique_elements, counts_elements)))\n",
    "\n",
    "# Label statistics\n",
    "print(\"Labels Mean: \", np.mean(y_train))\n",
    "print(\"Labels Std Dev: \", np.std(y_train))\n",
    "print(\"Labels Min: \", np.min(y_train))\n",
    "print(\"Labels Max: \", np.max(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce52f40-d209-44a9-9603-895ebaef648f",
   "metadata": {},
   "source": [
    "## Scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15bbdfae-0a32-4746-acd1-716f52eb373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled training features: [ 2.48689958e-17 -2.88657986e-17  1.03250741e-17  1.77635684e-17\n",
      " -3.99680289e-18]\n",
      "Std of scaled training features: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Mean of scaled training features:\", np.mean(X_train_scaled, axis=0)[:5])  # First 5 features\n",
    "print(\"Std of scaled training features:\", np.std(X_train_scaled, axis=0)[:5])  # First 5 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592f7fe-1265-4121-94d7-4f7cc9d66cf6",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "### Method 1: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea0904-1550-4b4e-9eca-95e77d9e1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the training set (to see training performance)\n",
    "y_train_pred = log_reg.predict(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Logistic Regression Training Accuracy:\", train_accuracy)\n",
    "print(\"Logistic Regression Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c2b6f-9764-486a-9b68-e641af1f10b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
