{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4aedfdd-146c-4dc3-b702-ce383dbb937e",
   "metadata": {},
   "source": [
    "# PART 3: Prediction of the winner of an NBA game\n",
    "\n",
    "The goal of this exercise is to develop and fine-tune predictive models that can accurately determine the outcome of basketball games based on data available at halftime. We will do so by training two different model and opposing them on a provided test set to estimate which one has an accuracy superior to 0.84.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e2418-fd73-4c70-b056-4d49b0bda181",
   "metadata": {},
   "source": [
    "## Studying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f9c6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import section\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from typing import Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a74ea34-b670-42c6-ad19-419f3a7c084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's now loads the different datasets\n",
    "\"\"\"\n",
    "\n",
    "# Load the datasets\n",
    "X_train = np.load('X_train.npy') #features\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy') #labels\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99922aaa-9031-458f-afed-b713794a3116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set features shape: (500, 50)\n",
      "Test set features shape: (500, 50)\n",
      "Training set labels shape: (500,)\n",
      "Test set labels shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the loaded arrays to understand the dimensions of the data\n",
    "print(\"Training set features shape:\", X_train.shape)\n",
    "print(\"Test set features shape:\", X_test.shape)\n",
    "print(\"Training set labels shape:\", y_train.shape)\n",
    "print(\"Test set labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3ee27-a696-4ace-92cc-7800d61081bb",
   "metadata": {},
   "source": [
    "---\n",
    "We now know that there are 500 samples under 50 different features on both of the features sets\n",
    "\n",
    "And we have 500 samples on the labels sets\n",
    "\n",
    "If we study some features on the datasets, mostly in the labels distributions, we can notice that If we study some features in the datasets, particularly focusing on the labels distributions, we can notice that the dataset is almost perfectly balanced with a slight advantage towards away wins (-1.0) over home wins (1.0), as indicated by 256 away wins compared to 244 home wins.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93a659c0-54d7-4510-a562-53ed1504405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution:  {-1.0: 256, 1.0: 244}\n",
      "Labels Mean:  -0.024\n",
      "Labels Std Dev:  0.9997119585160518\n",
      "Labels Min:  -1.0\n",
      "Labels Max:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Check for class distributions in the labels\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"Label Distribution: \", dict(zip(unique_elements, counts_elements)))\n",
    "\n",
    "# Label statistics\n",
    "print(\"Labels Mean: \", np.mean(y_train))\n",
    "print(\"Labels Std Dev: \", np.std(y_train))\n",
    "print(\"Labels Min: \", np.min(y_train))\n",
    "print(\"Labels Max: \", np.max(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce52f40-d209-44a9-9603-895ebaef648f",
   "metadata": {},
   "source": [
    "## Scaling the dataset\n",
    "\n",
    "We need to preprocess the data because it ensures that the model receives data in a format that optimizes its ability to learn patterns and make accurate predictions. This includes scaling features to the same range.\n",
    "\n",
    "After the preprocessing, we can see that the features are normalized, making them directly comparable and preventing any single feature from disproportionately influencing the model due to its scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15bbdfae-0a32-4746-acd1-716f52eb373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled training features: [ 2.48689958e-17 -2.88657986e-17  1.03250741e-17  1.77635684e-17\n",
      " -3.99680289e-18]\n",
      "Std of scaled training features: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Mean of scaled training features:\", np.mean(X_train_scaled, axis=0)[:5])  # First 5 features\n",
    "print(\"Std of scaled training features:\", np.std(X_train_scaled, axis=0)[:5])  # First 5 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592f7fe-1265-4121-94d7-4f7cc9d66cf6",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "We will compare two methods to train our models: The Logistic Regression and Support Vector Classifier (SVC), to identify which offers superior performance in predicting basketball game outcomes based on halftime data.\n",
    "\n",
    "### Method 1: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ea0904-1550-4b4e-9eca-95e77d9e1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.894\n",
      "Logistic Regression Test Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = log_reg.predict(X_train_scaled) # training set\n",
    "y_test_pred = log_reg.predict(X_test_scaled) # test set\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Logistic Regression Training Accuracy:\", train_accuracy)\n",
    "print(\"Logistic Regression Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f381f2c-489f-41a9-85d1-b645750362a1",
   "metadata": {},
   "source": [
    "### Method 2: Train SVC - Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba80a66-dd5b-4af7-8626-4a828f3e0e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Training Accuracy: 0.962\n",
      "SVC Test Accuracy: 0.876\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the support vector classifier\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred_svc = svc.predict(X_train_scaled) # training set\n",
    "y_test_pred_svc = svc.predict(X_test_scaled) # test set\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy_svc = accuracy_score(y_train, y_train_pred_svc)\n",
    "test_accuracy_svc = accuracy_score(y_test, y_test_pred_svc)\n",
    "\n",
    "print(\"SVC Training Accuracy:\", train_accuracy_svc)\n",
    "print(\"SVC Test Accuracy:\", test_accuracy_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3401c-45b0-4fad-a343-c483c13a58ee",
   "metadata": {},
   "source": [
    "---\n",
    "The SVC definitely seems a better candidate, because it has shown superior accuracy in the initial tests.\n",
    "\n",
    "So let's try to optimize it by fine tuning the hyper-parameters using the Grid Search, which is a systematic approach to parameter tuning that methodically builds and evaluates a model for each combination of algorithm parameters specified in a grid.\n",
    "\n",
    "\n",
    "## Fine tuning the SVC hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee5aeb-8939-487f-8936-f196c8ce1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_svc_hyperparameters(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[SVC, float, float]:\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for an SVC model using GridSearchCV and evaluates the optimized model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: ndarray, feature matrix for training data.\n",
    "    - y_train: ndarray, labels for training data.\n",
    "    - X_test: ndarray, feature matrix for test data.\n",
    "    - y_test: ndarray, labels for test data.\n",
    "    \n",
    "    Returns:\n",
    "    - best_svc: The SVC model with the best found hyperparameters.\n",
    "    - best_cv_accuracy: The best cross-validation accuracy achieved during tuning.\n",
    "    - test_accuracy: Accuracy of the best SVC model on the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "    param_grid2 = {\n",
    "        'C': [0.1, 1, 10, 50, 100, 500],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1, 5, 10],\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'degree': [2, 3, 4]  # Only relevant for 'poly' kernel\n",
    "    }\n",
    "    \n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_svc = grid_search.best_estimator_ # Extract the best SVC model\n",
    "    best_cv_accuracy = grid_search.best_score_ #cross-validation\n",
    "    \n",
    "    # Predict on the test set with the optimized model\n",
    "    y_test_pred_optimized = best_svc.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred_optimized)\n",
    "    \n",
    "    return best_svc, best_cv_accuracy, test_accuracy, y_test_pred_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82bcc67-d5b0-4dd1-b55e-cddf56822110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the tuned svc function\n",
    "best_svc, best_cv_accuracy, test_accuracy, y_test_pred_optimized = tune_svc_hyperparameters(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"Best Cross-Validation Accuracy:\", best_cv_accuracy)\n",
    "print(\"Test Accuracy of the Optimized SVC Model:\", test_accuracy)\n",
    "#print(\"Best Model Parameters:\", best_svc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9d9ed-27bb-458b-92ad-3eb9eddf5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a classification report for the optimized SVC model on the test data\n",
    "report = classification_report(y_test, y_test_pred_optimized, target_names=['Away Win', 'Home Win'])\n",
    "\n",
    "print(\"Classification Report for the Optimized SVC Model:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1b4a2-7d04-4610-be98-eac0a9e97f80",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "The SVC demonstrated a suitable performance at predicting the outcomes of basketball games based on halftime data, achieving a test accuracy of 0.876 and a cross-validation accuracy of 0.846. Notably, the model showed a balanced ability to predict both 'Home Win' and 'Away Win' scenarios, as proved by F1-scores of 0.87 and 0.83, respectively. These metrics suggest that the SVC effectively captures the underlying patterns within the halftime data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d561a-1fb5-4e22-852e-462fce9b9020",
   "metadata": {},
   "source": [
    "## Fine-tuning the Logistic regression\n",
    "\n",
    "As for comparison purpose, we should also push forward the optimization of the hyperparameters of the logistic regression model, ensuring a level playing field in evaluating its performance against the SVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a9ea7-b507-46a6-bb7a-3ed8f3e93223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_logistic_regression_hyperparameters(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[LogisticRegression, Dict[str, Any], float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for a Logistic Regression model using GridSearchCV and evaluates the optimized model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: ndarray, feature matrix for training data.\n",
    "    - y_train: ndarray, labels for training data.\n",
    "    - X_test: ndarray, feature matrix for test data.\n",
    "    - y_test: ndarray, labels for test data.\n",
    "    \n",
    "    Returns:\n",
    "    - best_lr: The Logistic Regression model with the best found hyperparameters.\n",
    "    - best_params: The best hyperparameters found by GridSearchCV.\n",
    "    - test_accuracy: Accuracy of the best Logistic Regression model on the test data.\n",
    "    - y_test_pred_lr_optimized: Predictions made by the optimized model on the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid_lr = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "    param_grid_lr2 = {\n",
    "        'C': [0.01, 0.1, 1, 10, 50, 100, 500],  # Expanded range of C values\n",
    "        'penalty': ['l1', 'l2'],  # Including both l1 and l2 penalties\n",
    "        'solver': ['liblinear', 'saga'],  # Including solvers that support both penalties. 'saga' supports elastic-net as well.\n",
    "        'max_iter': [100, 200, 500]  # To ensure convergence for larger C values or more complex data\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy', verbose=4)\n",
    "    grid_search_lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract the best model and parameters\n",
    "    best_lr = grid_search_lr.best_estimator_\n",
    "    best_params = grid_search_lr.best_params_\n",
    "    \n",
    "    # Predict on the test set with the optimized model\n",
    "    y_test_pred_lr_optimized = best_lr.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred_lr_optimized)\n",
    "    \n",
    "    return best_lr, best_params, test_accuracy, y_test_pred_lr_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ea7f0-c277-40be-9053-5a0746162778",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr, best_params_lr, test_accuracy_lr, y_test_pred_lr_optimized = tune_logistic_regression_hyperparameters(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "# Print the best parameters and test accuracy\n",
    "print(\"Best Parameters for Logistic Regression:\", best_params_lr)\n",
    "print(\"Optimized Logistic Regression Test Accuracy:\", test_accuracy_lr)\n",
    "\n",
    "# Generate and print the classification report, including the F1-score\n",
    "classification_report_lr = classification_report(y_test, y_test_pred_lr_optimized, target_names=['Away Win', 'Home Win'])\n",
    "print(\"Classification Report for the Optimized Logistic Regression Model:\\n\", classification_report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769557a6-43cb-4cd6-993a-be8dd41a279a",
   "metadata": {},
   "source": [
    "# Final overview\n",
    "\n",
    "The fine-tuning of the logistic regression showed us a test accuracy of 0.836, which is close but doesnt achieve the required performance of 0.84. Despite the promising training accuracy of 0.894, the weak point of the logistic regression is in the prediction of the result for the home team.\n",
    "\n",
    "In a concise comparison, the SVC model outperforms Logistic Regression in terms of overall test accuracy and demonstrates balanced precision and recall across classes, with an accuracy of 0.856 compared to 0.836 for the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aff116-7644-4af5-b51d-83d362165078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
